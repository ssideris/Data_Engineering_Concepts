## Data & Operations

DataOps, short for Data Operations, is a transformative approach that bridges the gap between data engineering, data science, and IT operations. It aims to enhance collaboration, streamline workflows, and automate processes, all in the pursuit of making data more accessible, reliable, and agile.

A suggested structure of studying the tutorials:

### 1) Setting up a Virtual Machine in Google Cloud

The scope of this tutorial is to enhance the specifications of our working environment easily by using a VM provided by Google Cloud:
[Virtual Machine Instance Creation using Google Cloud](https://github.com/ssideris/Data_Management_and_Analytics_Operations/tree/main/DataOps/Virtual%20Machine%20Instance%20Creation%20using%20Google%20Cloud.pdf)

### 2) Setting up a Postgres Database using Docker

The scope of this tutorial is to show how to set up a postgres database, use it and share it with others, in minutes, using an image provided by Docker Hub:
[Deployment of a PostgreSQL Database using Docker](https://github.com/ssideris/Data_Management_and_Analytics_Operations/tree/main/DataOps/Deployment%20of%20a%20PostgreSQL%20Database%20using%20Docker)

### 3) What is Containerization via Docker and how to create a Network of Data Procedures - Containers

The scope of this tutorial is to explain the concept of Containerization using Docker and how it benefits the streamlining of Data procedures:
[Containerizing Python Scripts and Developing a Containers Network using Docker & Docker Compose](https://github.com/ssideris/Data_Management_and_Analytics_Operations/tree/main/DataOps/Containerizing%20Python%20Scripts%20and%20Developing%20a%20Containers%20Network%20using%20Docker%20%26%20Docker%20Compose)

### 4) What is Flow-as-a-Code and how to monitor it using Prefect

The scope of this tutorial is to explain what is Flow-as-a-Code, how it benefits Data Pipelines over traditional Flows and how to effectively monitor them using Prefect:
[Monitoring a Flow-as-a-Code using Prefect](https://github.com/ssideris/Data_Management_and_Analytics_Operations/tree/main/DataOps/Flow-as-a-Code%20Monitoring%20using%20Prefect)

### 5) Deploying a Flow-as-a-Code using Prefect

The scope of this tutorial is to show the step-by-step deployment of a Flow-as-a-Code using Prefect, from scheduling and parameterization to containerization and version controlling:
[Flow-as-a-Code Deployment using Prefect]([https://github.com/ssideris/Data_Management_and_Analytics_Operations/edit/main/DataOps/README.md](https://github.com/ssideris/Data_Management_and_Analytics_Operations/tree/main/DataOps/Flow-as-a-Code%20Deployment%20using%20Prefect))

### 6) Using Google Cloud's Data Lake and Data Warehouse Capabilities 

The scope of this tutorial is to harness the power of Google Cloud by loading Data to Cloud Storage and querying them using BigQuery:
[Uploading Data on Google Cloud Storage and Querying them Using BigQuery](https://github.com/ssideris/Data_Management_and_Analytics_Operations/tree/main/DataOps/Uploading%20Data%20in%20Google%20Cloud%20Storage%20and%20Querying%20them%20using%20Big%20Query)

### 7) Analytics Engineering using dbt

The scope of this tutorial is to explaing the concept of Analytics Engineering and how it boosts the collaboration between data engineers and data analysts. The tool to be used is dbt:
[Analytics Engineering using dbt](https://github.com/ssideris/Data_Management_and_Analytics_Operations/blob/main/DataOps/Analytics%20Engineering%20using%20dbt/README.md)

### 8) Batch Processing using PySpark (UNDER CONSTRUCTION)
